{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment, we will work with the *Adult* data set. Please download the data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult). Extract the data files into the subdirectory: `../05_src/data/adult/` (relative to `./05_src/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Assuming that the files `adult.data` and `adult.test` are in `../05_src/data/adult/`, then you can use the code below to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv \n",
    "# Add src to path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "    'native-country', 'income'\n",
    "]\n",
    "adult_dt = (pd.read_csv(r'C:\\UFT data science program\\DSI_1\\scaling_to_production\\05_src\\data\\adult\\adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and Y\n",
    "\n",
    "Create the features data frame and target data:\n",
    "\n",
    "+ Create a dataframe `X` that holds the features (all columns that are not `income`).\n",
    "+ Create a dataframe `Y` that holds the target data (`income`).\n",
    "+ From `X` and `Y`, obtain the training and testing data sets:\n",
    "\n",
    "    - Use a train-test split of 70-30%. \n",
    "    - Set the random state of the splitting function to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22792, 14)\n",
      "X_test shape: (9769, 14)\n",
      "Y_train shape: (22792,)\n",
      "Y_test shape: (9769,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into features (X) and target (Y)\n",
    "X = adult_dt.drop(columns='income')  # All columns except 'income'\n",
    "Y = adult_dt['income']  # The 'income' column\n",
    "\n",
    "# Split the data into training and testing sets with a 70-30% ratio\n",
    "# Setting random_state=42 for reproducibility\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shape of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(r'C:\\UFT data science program\\DSI_1\\scaling_to_production\\05_src\\data\\adult\\adult.data', header = None, names = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random States\n",
    "\n",
    "Please comment: \n",
    "\n",
    "+ What is the [random state](https://scikit-learn.org/stable/glossary.html#term-random_state) of the [splitting function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)? \n",
    "+ Why is it [useful](https://en.wikipedia.org/wiki/Reproducibility)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Comment here.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the random state of the splitting function?\n",
    "The random_state parameter in the train_test_split function is used to control the shuffling of the data before splitting it into training and testing sets. Setting a specific random_state ensures that the split is reproducible, meaning you get the same split every time you run the code with that specific random_state value.\n",
    "\n",
    "Why is it useful?\n",
    "Setting the random_state parameter in data splitting functions like train_test_split enhances reproducibility, stability, and fairness in model comparison and evaluation. It ensures that the randomness in your experiments is controlled and consistent, making your work more robust, reliable, and easier to validate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create a [Column Transformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) that treats the features as follows:\n",
    "\n",
    "- Numerical variables\n",
    "\n",
    "    * Apply [KNN-based imputation for completing missing values](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html):\n",
    "        \n",
    "        + Consider the 7 nearest neighbours.\n",
    "        + Weight each neighbour by the inverse of its distance, causing closer neigbours to have more influence than more distant ones.\n",
    "    * [Scale features using statistics that are robust to outliers](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler).\n",
    "\n",
    "- Categorical variables: \n",
    "    \n",
    "    * Apply a [simple imputation strategy](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer):\n",
    "\n",
    "        + Use the most frequent value to complete missing values, also called the *mode*.\n",
    "\n",
    "    * Apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html):\n",
    "        \n",
    "        + Handle unknown labels if they exist.\n",
    "        + Drop one column for binary variables.\n",
    "    \n",
    "    \n",
    "The column transformer should look like this:\n",
    "\n",
    "![](./images/assignment_2__column_transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  KNNImputer(n_neighbors=7,\n",
       "                                                             weights=&#x27;distance&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 Index([&#x27;numerical1&#x27;, &#x27;numerical2&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 Index([&#x27;categorical1&#x27;, &#x27;categorical2&#x27;], dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  KNNImputer(n_neighbors=7,\n",
       "                                                             weights=&#x27;distance&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 Index([&#x27;numerical1&#x27;, &#x27;numerical2&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 Index([&#x27;categorical1&#x27;, &#x27;categorical2&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_transforms</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;numerical1&#x27;, &#x27;numerical2&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer(n_neighbors=7, weights=&#x27;distance&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_transforms</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;categorical1&#x27;, &#x27;categorical2&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num_transforms',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  KNNImputer(n_neighbors=7,\n",
       "                                                             weights='distance')),\n",
       "                                                 ('scaler', RobustScaler())]),\n",
       "                                 Index(['numerical1', 'numerical2'], dtype='object')),\n",
       "                                ('cat_transforms',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                handle_unknown='ignore'))]),\n",
       "                                 Index(['categorical1', 'categorical2'], dtype='object'))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data frame to identify numerical and categorical columns\n",
    "# Replace this with your actual dataframe\n",
    "df = pd.DataFrame({\n",
    "    'numerical1': [1.0, 2.0, None, 4.0],\n",
    "    'numerical2': [10, 20, None, 40],\n",
    "    'categorical1': ['A', 'B', None, 'A'],\n",
    "    'categorical2': ['X', None, 'Y', 'Y']\n",
    "})\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define the transformer for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=7, weights='distance')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Define the transformer for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "])\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_transforms', numerical_transformer, numerical_features),\n",
    "        ('cat_transforms', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "preprocessor\n",
    "# Example of how to apply this preprocessor to a dataset\n",
    "# transformed_df = preprocessor.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "Create a [model pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): \n",
    "\n",
    "+ Add a step labelled `preprocessing` and assign the Column Transformer from the previous section.\n",
    "+ Add a step labelled `classifier` and assign a [`RandomForestClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to it.\n",
    "\n",
    "The pipeline looks like this:\n",
    "\n",
    "![](./images/assignment_2__pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num_transforms&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer(n_neighbors=7,\n",
       "                                                                              weights=&#x27;distance&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  Index([&#x27;39&#x27;, &#x27; 77516&#x27;, &#x27; 13&#x27;, &#x27; 2174&#x27;, &#x27; 0&#x27;, &#x27; 40&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_transforms&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  Index([&#x27; State-gov&#x27;, &#x27; Bachelors&#x27;, &#x27; Never-married&#x27;, &#x27; Adm-clerical&#x27;,\n",
       "       &#x27; Not-in-family&#x27;, &#x27; White&#x27;, &#x27; Male&#x27;, &#x27; United-States&#x27;, &#x27; &lt;=50K&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num_transforms&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   KNNImputer(n_neighbors=7,\n",
       "                                                                              weights=&#x27;distance&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  Index([&#x27;39&#x27;, &#x27; 77516&#x27;, &#x27; 13&#x27;, &#x27; 2174&#x27;, &#x27; 0&#x27;, &#x27; 40&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat_transforms&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  Index([&#x27; State-gov&#x27;, &#x27; Bachelors&#x27;, &#x27; Never-married&#x27;, &#x27; Adm-clerical&#x27;,\n",
       "       &#x27; Not-in-family&#x27;, &#x27; White&#x27;, &#x27; Male&#x27;, &#x27; United-States&#x27;, &#x27; &lt;=50K&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;model&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  KNNImputer(n_neighbors=7,\n",
       "                                                             weights=&#x27;distance&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, RobustScaler())]),\n",
       "                                 Index([&#x27;39&#x27;, &#x27; 77516&#x27;, &#x27; 13&#x27;, &#x27; 2174&#x27;, &#x27; 0&#x27;, &#x27; 40&#x27;], dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;cat_transforms&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 Index([&#x27; State-gov&#x27;, &#x27; Bachelors&#x27;, &#x27; Never-married&#x27;, &#x27; Adm-clerical&#x27;,\n",
       "       &#x27; Not-in-family&#x27;, &#x27; White&#x27;, &#x27; Male&#x27;, &#x27; United-States&#x27;, &#x27; &lt;=50K&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_transforms</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;39&#x27;, &#x27; 77516&#x27;, &#x27; 13&#x27;, &#x27; 2174&#x27;, &#x27; 0&#x27;, &#x27; 40&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer(n_neighbors=7, weights=&#x27;distance&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_transforms</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27; State-gov&#x27;, &#x27; Bachelors&#x27;, &#x27; Never-married&#x27;, &#x27; Adm-clerical&#x27;,\n",
       "       &#x27; Not-in-family&#x27;, &#x27; White&#x27;, &#x27; Male&#x27;, &#x27; United-States&#x27;, &#x27; &lt;=50K&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num_transforms',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   KNNImputer(n_neighbors=7,\n",
       "                                                                              weights='distance')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  Index(['39', ' 77516', ' 13', ' 2174', ' 0', ' 40'], dtype='object')),\n",
       "                                                 ('cat_transforms',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(drop='if_binary',\n",
       "                                                                                 handle_unknown='ignore'))]),\n",
       "                                                  Index([' State-gov', ' Bachelors', ' Never-married', ' Adm-clerical',\n",
       "       ' Not-in-family', ' White', ' Male', ' United-States', ' <=50K'],\n",
       "      dtype='object'))])),\n",
       "                ('model', RandomForestClassifier())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Step 1: Load your actual DataFrame\n",
    "file_path = r'C:\\UFT data science program\\DSI_1\\scaling_to_production\\05_src\\data\\adult\\adult.data'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Identify numerical and categorical columns\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define the transformer for numerical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=7, weights='distance')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Define the transformer for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "])\n",
    "\n",
    "\n",
    "# Step 5: Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_transforms', numerical_transformer, numerical_features),\n",
    "        ('cat_transforms', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 6: Create a pipeline with preprocessing and classifier\n",
    "pipe_simple = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Display the pipeline\n",
    "pipe_simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Evaluate the model pipeline using [`cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html):\n",
    "\n",
    "+ Measure the following [preformance metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values): negative log loss, ROC AUC, accuracy, and balanced accuracy.\n",
    "+ Report the training and validation results. \n",
    "+ Use five folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_neg_log_loss  train_neg_log_loss  test_roc_auc  \\\n",
      "0  12.151813    0.227012          -0.379297           -0.080600      0.893879   \n",
      "1  12.482668    0.238467          -0.346505           -0.081736      0.904273   \n",
      "2  12.457520    0.255141          -0.372077           -0.081460      0.902922   \n",
      "3  12.464814    0.238467          -0.377147           -0.082766      0.905758   \n",
      "4  12.444925    0.230608          -0.362360           -0.082112      0.904750   \n",
      "\n",
      "   train_roc_auc   test_f1  train_f1  test_accuracy  train_accuracy  \\\n",
      "0            1.0  0.646394       1.0       0.843762             1.0   \n",
      "1            1.0  0.672559       1.0       0.850672             1.0   \n",
      "2            1.0  0.653328       1.0       0.847025             1.0   \n",
      "3            1.0  0.677615       1.0       0.856786             1.0   \n",
      "4            1.0  0.684188       1.0       0.859282             1.0   \n",
      "\n",
      "   test_precision  train_precision  test_recall  train_recall  experiment  \n",
      "0        0.709924              1.0     0.593301           1.0           1  \n",
      "1        0.712121              1.0     0.637161           1.0           1  \n",
      "2        0.718660              1.0     0.598884           1.0           1  \n",
      "3        0.739623              1.0     0.625199           1.0           1  \n",
      "4        0.744142              1.0     0.633174           1.0           1  \n",
      "\n",
      "Test Set Accuracy: 0.8586\n",
      "\n",
      "Test Set Detailed Metrics:\n",
      "Accuracy: 0.8586\n",
      "Precision: 0.7404\n",
      "Recall: 0.6372\n",
      "F1 Score: 0.6849\n",
      "ROC AUC: 0.9040\n",
      "Log Loss: 0.3857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Define the scoring metrics\n",
    "scoring = ['neg_log_loss', 'roc_auc', 'f1', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "#  Perform cross-validation on the training set\n",
    "res_simple_dict = cross_validate(\n",
    "    pipe_simple,\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    cv=5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#  Convert the results dictionary to a DataFrame and add an 'experiment' column\n",
    "res_simple = pd.DataFrame(res_simple_dict).assign(experiment=1)\n",
    "\n",
    "# Display the cross-validation results\n",
    "print(res_simple)\n",
    "\n",
    "#  Evaluate the fitted model on the test set\n",
    "pipe_simple.fit(X_train, Y_train)\n",
    "test_score = pipe_simple.score(X_test, Y_test)\n",
    "print(f\"\\nTest Set Accuracy: {test_score:.4f}\")\n",
    "\n",
    "# Detailed evaluation on the test set\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "Y_pred = pipe_simple.predict(X_test)\n",
    "Y_proba = pipe_simple.predict_proba(X_test)[:, 1]  # For ROC AUC and log loss\n",
    "\n",
    "print(\"\\nTest Set Detailed Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(Y_test, Y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(Y_test, Y_pred):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(Y_test, Y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(Y_test, Y_proba):.4f}\")\n",
    "print(f\"Log Loss: {log_loss(Y_test, Y_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fold-level results as a pandas data frame and sorted by negative log loss of the test (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results Sorted by Negative Log Loss (Validation Set):\n",
      "   fold  test_neg_log_loss  test_roc_auc   test_f1  test_accuracy  \\\n",
      "1     2          -0.346505      0.904273  0.672559       0.850672   \n",
      "4     5          -0.362360      0.904750  0.684188       0.859282   \n",
      "2     3          -0.372077      0.902922  0.653328       0.847025   \n",
      "3     4          -0.377147      0.905758  0.677615       0.856786   \n",
      "0     1          -0.379297      0.893879  0.646394       0.843762   \n",
      "\n",
      "   test_precision  test_recall  \n",
      "1        0.712121     0.637161  \n",
      "4        0.744142     0.633174  \n",
      "2        0.718660     0.598884  \n",
      "3        0.739623     0.625199  \n",
      "0        0.709924     0.593301  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add fold number to the DataFrame for clarity\n",
    "res_simple['fold'] = range(1, len(res_simple) + 1)\n",
    "\n",
    "#  Sort the DataFrame by the negative log loss of the test set\n",
    "sorted_res_simple = res_simple.sort_values(by='test_neg_log_loss', ascending=False)\n",
    "\n",
    "#  Display the sorted DataFrame\n",
    "print(\"Cross-Validation Results Sorted by Negative Log Loss (Validation Set):\")\n",
    "print(sorted_res_simple[['fold', 'test_neg_log_loss', 'test_roc_auc', 'test_f1', \n",
    "                         'test_accuracy', 'test_precision', 'test_recall']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of each metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Metrics:\n",
      "fit_time              12.343289\n",
      "score_time             0.238833\n",
      "test_neg_log_loss     -0.367477\n",
      "train_neg_log_loss    -0.081735\n",
      "test_roc_auc           0.902316\n",
      "train_roc_auc          1.000000\n",
      "test_f1                0.666817\n",
      "train_f1               1.000000\n",
      "test_accuracy          0.851505\n",
      "train_accuracy         1.000000\n",
      "test_precision         0.724894\n",
      "train_precision        1.000000\n",
      "test_recall            0.617544\n",
      "train_recall           1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the mean of each metric\n",
    "mean_metrics = res_simple.mean()\n",
    "\n",
    "# Display the mean metrics\n",
    "print(\"Mean Cross-Validation Metrics:\")\n",
    "print(mean_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the same performance metrics (negative log loss, ROC AUC, accuracy, and balanced accuracy) using the testing data `X_test` and `Y_test`. Display results as a dictionary.\n",
    "\n",
    "*Tip*: both, `roc_auc()` and `neg_log_loss()` will require prediction scores from `pipe.predict_proba()`. However, for `roc_auc()` you should only pass the last column `Y_pred_proba[:, 1]`. Use `Y_pred_proba` with `neg_log_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance Metrics:\n",
      "{'neg_log_loss': -0.3857076055170705, 'roc_auc': 0.9039583548539247, 'accuracy': 0.8585905112851221, 'balanced_accuracy': 0.7830749488464662}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  Predict probabilities and class labels on the testing data\n",
    "Y_pred_proba = pipe_simple.predict_proba(X_test)  # Probability predictions\n",
    "Y_pred = pipe_simple.predict(X_test)              # Class predictions\n",
    "\n",
    "#  Calculate performance metrics\n",
    "test_metrics = {\n",
    "    'neg_log_loss': -log_loss(Y_test, Y_pred_proba),             # Negative log loss\n",
    "    'roc_auc': roc_auc_score(Y_test, Y_pred_proba[:, 1]),        # ROC AUC score\n",
    "    'accuracy': accuracy_score(Y_test, Y_pred),                  # Accuracy\n",
    "    'balanced_accuracy': balanced_accuracy_score(Y_test, Y_pred) # Balanced accuracy\n",
    "}\n",
    "\n",
    "# Display the calculated metrics\n",
    "print(\"Test Set Performance Metrics:\")\n",
    "print(test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Recoding\n",
    "\n",
    "In the first code chunk of this document, we loaded the data and immediately recoded the target variable `income`. Why is this [convenient](https://scikit-learn.org/stable/modules/model_evaluation.html#binary-case)?\n",
    "\n",
    "The specific line was:\n",
    "\n",
    "```\n",
    "adult_dt = (pd.read_csv('../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Answer here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_2_rubric_clean.xlsx) contains the criteria for assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
